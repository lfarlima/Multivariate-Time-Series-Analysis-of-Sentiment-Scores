{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fintech Project 2 Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lfarlima/Project-2/blob/main/Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaVkHMLGVW4u"
      },
      "source": [
        "##Imports and Dependencies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5ra-jqchjzO"
      },
      "source": [
        "#imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from newsapi import NewsApiClient\n",
        "from dotenv import load_dotenv\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "analyzer=SentimentIntensityAnalyzer\n",
        "import pathlib as path\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import yfinance as yf # Stock data\n",
        "from numpy.random import seed\n",
        "seed (1)\n",
        "from tensorflow import random\n",
        "random.set_seed(2)\n",
        "\n",
        "from nltk.corpus import stopwords, reuters\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Code to download corpora\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('reuters')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "api_key = \"0ef1c61926f54984abcca4338225fd66\"\n",
        "\n",
        "# Download/Update the VADER Lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "newsapi = NewsApiClient(api_key=api_key)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKpH4gkKjZ"
      },
      "source": [
        "## Twitter Tweet's sentiment analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsnkthtwiIW1"
      },
      "source": [
        "# pip install nest_asyncio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okU7lNqDyZlL"
      },
      "source": [
        "# pip install --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJf186GDykB8"
      },
      "source": [
        "# import twint\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "# c= twint.Config()\n",
        "# c.Search= \"ETH\" or \"Ethereum\"\n",
        "# c.Since= \"2020-09-29\"\n",
        "# c.Until = '2021-04-04'\n",
        "# # c.Limit= 1000\n",
        "# c.Lang= \"en\"\n",
        "# c.Store_csv= True\n",
        "# c.Output= \"Search.csv\"\n",
        "# twint.run.Search(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l04y6SsgjZ7"
      },
      "source": [
        "# df = pd.read_csv('Search.csv', encoding=\"utf-8-sig\")\n",
        "# df= df[[\"id\", \"created_at\", \"tweet\", \"language\"]]\n",
        "# df=df.loc[df[\"language\"]==\"en\"]\n",
        "# df=df.rename(columns={\"id\": \"ID\", \"created_at\": \"Date\", \"tweet\": \"Tweet\"})\n",
        "# df=df.drop([\"language\"], axis=1)\n",
        "# #need to standardize time \n",
        "# # df=df.set_index(\"Date\")\n",
        "# df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFJ5gAXxgjqt"
      },
      "source": [
        "# import local csv to colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iErUOtzFlXU_"
      },
      "source": [
        "pltr_twitter_df=pltr_twitter_df.sort_values('Date')\n",
        "pltr_twitter_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VpZBawplgKD"
      },
      "source": [
        " #Sentiment calculation based on compound score\n",
        "def get_sentiment(score):\n",
        "    \"\"\"\n",
        "    Calculates the sentiment based on the compound score.\n",
        "    \"\"\"\n",
        "    result = 0  # Neutral by default\n",
        "    if score >= 0.05:  # Positive\n",
        "        result = 1\n",
        "    elif score <= -0.05:  # Negative\n",
        "        result = -1\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fvvRErflkCz"
      },
      "source": [
        "pltr_twtr_sentiments = []\n",
        "\n",
        "for index, row in pltr_twitter_df.iterrows():\n",
        "    try:\n",
        "        text = row[\"Tweet\"]\n",
        "        date = row[\"Date\"]\n",
        "        sentiment = analyzer.polarity_scores(text)\n",
        "        compound = sentiment[\"compound\"]\n",
        "        pos = sentiment[\"pos\"]\n",
        "        neu = sentiment[\"neu\"]\n",
        "        neg = sentiment[\"neg\"]\n",
        "        pol=  get_sentiment(compound)\n",
        "        \n",
        "        pltr_twtr_sentiments.append({\n",
        "            \"text\": text,\n",
        "            \"date\": date,\n",
        "            \"compound\": compound,\n",
        "            \"positive\": pos,\n",
        "            \"negative\": neg,\n",
        "            \"neutral\": neu,\n",
        "            \"Polarity Score\":pol\n",
        "            \n",
        "        })\n",
        "        \n",
        "    except AttributeError:\n",
        "        pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfL5wXD6lne5"
      },
      "source": [
        "pltr_twitter_sentiment_df = pd.DataFrame(pltr_twtr_sentiments)\n",
        "\n",
        "pltr_twitter_sentiment_df=pltr_twitter_sentiment_df.sort_values('date')\n",
        "pltr_twitter_sentiment_df=pltr_twitter_sentiment_df.set_index('date')\n",
        "pltr_twitter_sentiment_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14-YB6xMlzKY"
      },
      "source": [
        "# import pltr_twitter_sentiment_df csv to colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gijTbZCXl21O"
      },
      "source": [
        "# Graph tallied Polarity Score \n",
        "pltr_twitter_sentiment_df.groupby('Polarity Score').size().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQs6NKuliK8g"
      },
      "source": [
        "## Pull data from Newsapi and run sentimment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZvPpnDilMU"
      },
      "source": [
        "pltr_headlines = newsapi.get_everything(\n",
        "    q=\"PLTR\",\n",
        "    language=\"en\",\n",
        "    page_size=10,\n",
        "    sort_by=\"relevancy\",\n",
        "    from_param=\"2021-02-29\"\n",
        ")\n",
        "\n",
        "pltr_headlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI66fxdMithr"
      },
      "source": [
        " # Transform the response dictionary to a DataFrame\n",
        "pltr_newsapi_df = pd.DataFrame.from_dict(pltr_headlines[\"articles\"])\n",
        "pltr_newsapi_df.head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BX4KddTiyqj"
      },
      "source": [
        "pltr_sentiments = []\n",
        "\n",
        "for article in pltr_headlines[\"articles\"]:\n",
        "    try:\n",
        "        text = article[\"content\"]\n",
        "        date = article[\"publishedAt\"][:10]\n",
        "        sentiment = analyzer.polarity_scores(text)\n",
        "        compound = sentiment[\"compound\"]\n",
        "        pos = sentiment[\"pos\"]\n",
        "        neu = sentiment[\"neu\"]\n",
        "        neg = sentiment[\"neg\"]\n",
        "        \n",
        "        pltr_sentiments.append({\n",
        "            \"text\": text,\n",
        "            \"date\": date,\n",
        "            \"compound\": compound,\n",
        "            \"positive\": pos,\n",
        "            \"negative\": neg,\n",
        "            \"neutral\": neu\n",
        "            \n",
        "        })\n",
        "        \n",
        "    except AttributeError:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3r_hmfrjfgN"
      },
      "source": [
        "# Create DataFrame\n",
        "pltr_newsapi_sentiment_df = pd.DataFrame(pltr_sentiments)\n",
        "\n",
        "# Reorder DataFrame columns\n",
        "cols = [\"date\", \"text\", \"compound\", \"positive\", \"negative\", \"neutral\"]\n",
        "pltr_newsapi_sentiment_df = pltr_newsapi_sentiment_df[cols]\n",
        "\n",
        "pltr_sentiment_newsapi_df.sort_values('date')\n",
        "pltr_sentiment_newsapi_df.set_index('date')\n",
        "pltr_sentiment_newsapi_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5-iGnA0joVY"
      },
      "source": [
        "# Graph tallied Polarity Score \n",
        "pltr_sentiment_newsapi_df.groupby('Polarity Score').size().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85smo6CFmfsx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lir7mM_hnHBJ"
      },
      "source": [
        "## WordCloud "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq89oq4ymhfy"
      },
      "source": [
        "df = pltr_twitter_sentiment_df[\"Polarity Score\"]\n",
        "#pltr_twitter_sentiment_df[pltr_twitter_sentiment_df[\"Polarity Score\"]=='-1']\n",
        "words = ' '.join(pltr_twitter_sentiment_df['text'])\n",
        "cleaned_word = \" \".join([word for word in words.split()\n",
        "                            if 'http' not in word\n",
        "                                and not word.startswith('@')\n",
        "                                and word != 'RT'\n",
        "                            ])\n",
        "stopwords = set(STOPWORDS)\n",
        "stopwords.add(\"PLTR\")\n",
        "stopwords.add(\"Palantir\")\n",
        "\n",
        "wordcloud = WordCloud(stopwords=stopwords,\n",
        "                      background_color='black',\n",
        "                      width=3000,\n",
        "                      height=2500\n",
        "                     ).generate(cleaned_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I31cg1Psmhhk"
      },
      "source": [
        "plt.figure(1,figsize=(12, 12))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkMm0SGVmhj_"
      },
      "source": [
        "#Do we use cumulative return of compound or polarity?\n",
        "c_return= (1 + pltr_twitter_sentiment_df['compound']).cumprod()\n",
        "c_return.head()\n",
        "\n",
        "pltr_twitter_sentiment_df.plot(kind='line', x='date', y='compound')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_8KmdzToSQY"
      },
      "source": [
        "## Yahoo Finance Stock API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8aSHqmfoWk2"
      },
      "source": [
        "# Load PLTR stock closing prices from YFinance\n",
        "pltr_yf = yf.download('PLTR',\n",
        "                       start='2020-01-01',\n",
        "                       end='2021-05-31',\n",
        "                       progress=False,\n",
        "                       index_col ='Date',\n",
        "                       infer_datetime_format= True,\n",
        "                       parse_dates = True,\n",
        "                       interval='1d'\n",
        "\n",
        ")\n",
        "pltr_df = pd.DataFrame(pltr_yf)\n",
        "pltr_df.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOpNdWDHoaD5"
      },
      "source": [
        "##Graph Sentiment score and Stock Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoeRLUPKogmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFb2LKehoqft"
      },
      "source": [
        "## ML and LSTM Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pOWXR71oyCN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}